\chapter{Literature Review}\label{chap:comp}

Complex-valued neural networks have been widely investigated since before the deep learning boom and have been found useful in the fields of adpative designing of patch antennas, neurophysiological analysis, and communications \cite{hirose2012complex}. 



Increased incorporation of complex-valued units in recent works of Recurrent Neural Networks (\cite{ArjovskySB15}, \cite{wisdom2016full}, \cite{danihelka2016associative}) and computer vision tasks(\cite{oyallon2015deep}, \cite{bruna2015theoretical}, \cite{worrall2017harmonic}) has brought significant attention to the virtues of complex-valued representations. 
%Kim and Adal and  Geogiou activation functions!!
%Guberman
%Akira
%rnn based approaches skipped brief mention?
%Neuronal synchrony
%better analysis of the techniques...
%interferometric radar....

 One of the
most important papers in this domain is [16], which gives
a mathematical motivation for complex-valued convolutional
neural networks, showing that they can be seen as nonlinear
multiwavelet packets, thus making the mathematical analysis
from the signal processing domain available for a rigorous
formulation of the properties of complex-valued convolu-
tional networks. 
 In [12] a wavelet
scattering network is proposed, which uses complex numbers

Complex numbers can be better utilized to represent natural phenomena. Utilizing complex-valued representations, Reichert and Serre (2013) \cite{reichert2013neuronal} developed neuronal units of a neural network inspired from a model of neuron in a human brain. In the Spiking Neuron Model, a neuron's output is expressed in terms of its firing rate and phase (relative time of its activity). The authors equated the firing rate with the magnitude and the neuron's phase as the phase of the neuron's output. Their implementation captures the concept of Neuronal Synchrony, which says that a neuron's time of firing (phase) also plays a role in information processing. The firing of a neuron happens on the basis of phases of the inputs such that synchronous (similar in phase) inputs produce an output while the asynchronous phases inhibits the output. This way the network tries to synchronize the phases of those inputs whose activations result in correct outputs. Takahiro and Takashi (2010) developed an output prediction system of a wind power generation using a $\mathbb{C}$-CNN where they expressed the wind information (wind speed and direction) by complex numbers, and use them as input and demonstrated that $\mathbb{C}$-CNN performed better as compared to $\mathbb{R}$-CNN, owing to the fact that complex nature of the data had a physical meaning behind it.
 
%SAR based
SARs are typically mounted on a moving platform, such as an aircraft or spacecraft, in order to capture 2D or 3D images of objects including landscapes. The capability of radars to operate in all-weather day-and-night conditions and make high and very high resolution images make them suitable for target classification, reconnaissance,
surveillance, etc. 
Chen $et \ al.$ propose A-ConvNet $\mathbb{R}$-CNN architecture which deviates from conventional $\mathbb{R}$-CNN in that it does away with the Fully Connected (FC) layers in order to decrease the number of parameters in an attempt to decrease over-fitting. They report state-of-the-art performance (99\% average accuracy) on classification of ten classes in teh Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset. This suggests the suitability of CNNs in classification of radar data. 

The recent re-introduction of complex-valued neural networks in the classification of Synthetic Aperture Radar (SAR) data has been very promising in the wake of marked advancements in the theory of deep learning. The data is complex by its very nature, hence opens up the interesting opportunity to employ $\mathbb{C}$-CNNs to better make use of phase information in various problems.

Wilmanski $et \ al.$ (2016) \cite{wilmanski2016complex} explore the suitability of using $\mathbb{C}$-CNNs for Automatic Target Recognition for complex-valued SAR data. Although their $\mathbb{C}$-CNN model had only one complex-valued layer (complex weights) in their complex-valued variant architecture, it outperformed (99.21\% accuracy) the state-of-the-art $\mathbb{R}$-CNN network (87.30\% accuracy). In the dataset they used (GOTCHA \cite{gotcha}), they also pointed out how the phase surrounding an object had a distinctive structure, pointing to the potential importance of phase information in classification tasks.

Polarimetric SAR (PolSAR) uses microwaves with different polarisations to measure the distance to ground and the reflectance of a target \cite{hansch2009classification}. Usually, PolSARs are installed on aeroplanes to It is of interest in a variety of applications to be able to correctly classify images according to their content. One of the traditional techniques for classification involving PolSAR data is the use of (real-valued) Multilayer Perceptrons (MLP). Inspired by the success of MLPs in computer vision, H\"{a}nsch and Hellwich (2009) \cite{hansch2009classification} employed the $\mathbb{C}$-NNs to classify the complex-valued Polarimetric Synthetic Aperture Radar (PolSAR) data to perform a 3-class pixel-wise classification (forest, fields and urban areas). The authors test their architectures using different error functions for $\mathbb{C}$-NNs, and compare $\mathbb{C}$-NNs with their real-valued counterparts. The results conclude that $\mathbb{C}$-NNs outperformed $\mathbb{R}$-CNNs in that particular problem. However, the input data to both type of CNNs is not preprocessed the same way. The same authors go ahead to tackle the object-classification problem using complex-valued convolutional neural networks ($\mathbb{C}$-CNNs) and $\mathbb{R}$-CNNs \cite{hansch2010complex}. They show that $\mathbb{C}$-CNNs, with only one complex-convolutional layer, outperform the $\mathbb{C}$-NNs in the cases where the number of neurons in single convolutional layer exceeded 10. Zhang $et \ al.$ (2017) \cite{polsarzhang2017complex} leverage magnitude as well as the phase of the PolSAR data to classify different terrains on the Flevoland (3 classes) and Oberpfaffenhofen datasets (15 classes). Compared to $\mathbb{R}$-CNN, $\mathbb{C}$-CNN performs better on both the datasets while having approximately same number of parameters.  

Guberman (2016) \cite{Guberman} in his work report the problems of convergence in complex-valued deep networks, presents a new activation function ($zReLU$), and demonstrates that complex-valued networks can better avoid over-fitting in training. 

%Deep Complex Networks
Chiheb $et \ al.$ (2018) \cite{trabelsi2018deep} compare the performance of different architectures of the $\mathbb{C}$-CNNs and $\mathbb{R}$-CNNs on the tasks of image recognition, music transcription, and speech spectrum prediction. $\mathbb{C}$-CNNs were reported to perform comparably to $\mathbb{R}$-CNNs for the first task, and achieve state-of-the-art performance on the two tasks while beating $\mathbb{R}$-CNNs. The authors also contribute the extension of Batch Normalization (BN) and Weight Initialization to complex domain. They report a lot of failed experiments when they used the modReLU and zReLU complex activation functions in the real-valued image classification problem due to the appearance of NaN(Not-A-Number) values caused by their non-complex-differentiable nature. 

%Discussion:

%In the light of the literature, we get a hint about the problem of convergence present in complex-valued deep learning related to analyticity of activation functions (\cite{trabelsi2018deep}, \cite{Guberman}), a problem which needs to be addressed. The recent success of $\mathbb{C}$-CNNs in PolSAR data classification task makes a compelling case for the use of complex-valued representations for radar data classification. 


The literature review brings to light the challenges of designing a $\mathbb{C}$-CNNs which include the choice of activation function and loss function while ensuring convergence, 





  