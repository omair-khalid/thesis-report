\chapter{Methodology} \label{chap:methodology}
 
This section details the methodology adopted to investigate the applicability of $\mathbb{C}$-CNNs to complex-natured data classification. 

\section{Approach}

In our experimentation, we aim to answer the following question:\\
 
 \textit{Can $\mathbb{C}$-$\mathrm{CNNs}$ outperform $\mathbb{R}$-$\mathrm{CNNs}$ in a complex-valued data classification problem, given that phase of the complex-natured input data contains, as well, discriminatory information?}\\
 
 The aims of our experimentation are:
 \begin{itemize}
 	\item To establish the importance of various complex-valued activation functions in $\mathbb{C}$-CNNs
 	\item To determine if $\mathbb{C}$-CNNs can better utilize phase information to produce better results than $\mathbb{R}$-CNNs
 	%\item To assess if $\mathbb{C}$-CNNs offer better generalization capability as compared to $\mathbb{R}$-CNNs
 \end{itemize}
 
 
 We employ two types of datasets: synthetically created toy data set which we call MNIST+P (Section \ref{data-mnistp}), and real-world Radar datasets (Section \ref{data-radar}), to feed into comparable $\mathbb{R}$-CNN and $\mathbb{C}$-CNN architectures in a bid to experimentally determine the winner in the complex-valued data classification problem. 
 
 MNIST+P dataset is created to test if additional information of phase can help increase classification accuracy of $\mathbb{C}$-CNNs more than that of $\mathbb{R}$-CNNs, under the assumption that the complex-nature data would be better exploited by $\mathbb{C}$-CNNs. In this case, we are sure that phase does contain meaningful information which can be leveraged to increase accuracy. 
 
 The real-world radar datasets are used for experimental verification of the deductions made from the results of MNIST+P dataset experiments, and to test applicability of $\mathbb{C}$-CNNs on FMCW radar data. 
 
 The architecture of $\mathbb{R}$-CNN and $\mathbb{C}$-CNN employed in this task is discussed in Section \ref{archdesc}.  All the experiments are conducted using Keras \cite{chollet2015keras} with Theano \cite{theano} backend.
 
 
 \section{Datasets}\label{datasets}
 
 
 \subsection{MNIST+P dataset}\label{data-mnistp}
 The MNIST database of handwritten digits (10 classes) has a training set of 60,000 examples, and a test set of 10,000 examples, where each image is of dimensions 28x28. It is a commonly used benchmark for supervised learning algorithm performance. In the MNIST+P dataset created for our experimentation, we consider that an image of MNIST dataset represents the magnitude of a complex number. Each pixel in an image is scaled such that the black part of the image corresponds to the value of 50, and the white part to 200. The phase for each image class (0,1,2,3,4,5,6,7,8,9) is picked from uniform distribution whose range is determined class-wise: The range for class 1 representing the digit 0 is [0,$\pi$/10], that for class 2 representing the digit 1 is [$\pi$/10,2$\pi$/10],...., that for class 10 representing digit 9 is [9$\pi$/10,$\pi$]. Each samples image in the dataset becomes complex natured i.e. having magnitude and phase values for each pixel.
 
   \begin{figure}[htb]
	\centering
	\epsfxsize=14cm
	{\epsfbox{mnistt.png}}\caption{LEFT: Examples of digits from MNIST Dataset; CENTER: Angle bin sector for each class; RIGHT: Depiction of phase channels corresponding to the classes shown in the left most image (color corresponds to angle sector in the center image) \cite{mnistimage}}
\label{fig:blocks}
\end{figure}
 
 \subsection{Radar datasets}\label{data-radar}
 
 Radar-150 and Radar-300 are two complex-valued datasets whose source is two FMCW radars with bandwidth of 6GHz and central frequencies of 150GHz (Type 2) and 300GHz (Type 1), respectively.
 Both the datasets contain scans of six static objects (bike , cone, dog, mannequin, sign, trolley), performed by rotating the radar around a single object at different angles. Total number of images in both the datasets are 813. In each class, the scans are taken at two different distances from the object i.e. 3.8m and 6.3m. Table 5.1 shows the data distribution among the classes. Appendices \ref{apa} and \ref{apb} show some examples of images present in the datasets. Radar-300 is present in Cartesian representation and Polar representation while Radar-150 is present in only Polar distribution. 
 
 
 
 %In our case, a triangular chirp is being produced at frequency of 150 GHz, with a bandwidth of 6 GHz
 
 \newcolumntype{?}{!{\vrule width 1.5pt}}
 \begin{table}
 	
 		\label{ta}
 		
 		
 	\begin{center}
 
 		\begin{tabular}{ c|c|c|c } 
 			%\hline
 			\textbf{class} & \textbf{3.8m} & \textbf{6.3m} & \textbf{Total}\\
 			\hline 
 			bike & 90 & 41&131\\
 			\hline
 			cone & 25 & 25 & 50\\
 			\hline 
 			dog & 46 & 46&92\\
 			\hline 
 			mannequin & 90 & 90&180\\
 			\hline 
 			sign & 90 & 90&180\\
 			\hline 
 			trolley & 90 & 90&180\\
 			
 			%\hline
 		\end{tabular}
 				\captionof{table}{Distribution of data over classes in Radar datasets}
 	\end{center}
 
 \end{table}

 \subsubsection{Preprocessing of Radar Dataset}
 We convert the Polar form information (magnitude and phase) to Cartesian form having a real channel and an imaginary channel. Now, the shape of each image becomes 32x32x2.
 

 \section{Architecture -- $\mathbb{R}$-CNNs \& $\mathbb{C}$-CNNs}\label{archdesc}
 The architecture employed for our experiments is a simplified variant of the one used by Chiheb $et \ al.$ (2018) \cite{trabelsi2018deep} for the problem of real-valued image classification. Our network contains three stages, each containing one residual block with 2 convolutional layers (3x3 filter size), 2 activation functions, and 2 BN layers in the order shown in Figure \ref{fig:blocks}. The skip connection of the first block differs from that of the second and the third block. The skip connection of the first block simply adds the input of the block to the output of the other thread of the block. However, the last two blocks perform a projection operation at their output: they convolve the input of the block with a 1x1 convolution operation with the same number of filters used throughout the stage, and concatenate it with the output of the other thread (with 2 conv, 2 BN, 2 activation layers) in a way that the distinction between real and imaginary parts remains. At the end of each stage, the number of filters are doubled. The architecture is illustrated in Figure \ref{fig:architecture}.
 
 
 %We hypothesize that since, $\mathbb{C}$-CNNs will be able to perform better than $\mathbb{R}$-CNNs, given the compelling reasons described in Section \ref{sect:moti}.


\begin{enumerate}
	\item \textit{Input :} The input is prepared such that the real and imaginary parts are separate channels, and reshaped to 2x32x32. The guiding principle in choosing the nature of input is that the information provided to both types of network should be presented in the same way i.e. feeding only real part to the $\mathbb{R}$-CNN and feeding both real and imaginary to the $\mathbb{C}$-CNN would be unfair, thus the same data is provided. 
	\item \textit{Convolution layer :} The convolution operation for $\mathbb{C}$-CNN and $\mathbb{R}$-CNN is described in Sections \ref{conv}.
	\item \textit{Weight initialization :} The kernels for $\mathbb{R}$-CNN are initialized using Glorot and Bengio (2010) criterion \cite{glorot2010understanding} described in \ref{gbwi}, while that of $\mathbb{R}$-CNN are initialized using Complex Weight Initialization scheme \cite{trabelsi2018deep} as described in Section \ref{cwi}.
	
	\item \textit{Activation function :} For $\mathbb{R}$-CNN, we choose the ReLU activation function, as it is currently the preferred choice in the community due to its state-of-the-art performance. For $\mathbb{C}$-CNN, we choose to test the performance of Real-Imaginary type -- $\mathrm{C}$ReLU, Phase-Magnitude type --  $z$ReLU, and the Transcendental type -- $\mathrm{tanh}(z)$.
	
	\item \textit{Batch normalization $(\mathrm{BN})$:} $\mathbb{R}$-CNN and $\mathbb{C}$-CNN employ the seperate BN processes as described in Section \ref{ssec:bn}.
	
	\item \textit{Average Pooling $(\mathrm{AP})$:} Both $\mathbb{R}$-CNN and $\mathbb{C}$-CNN employ average pooling of size (8,  8). Due to the drawback that a max-by-magnitude pooling would make sense only if the input is positive, we do not choose it. 
	
	\item \textit{Fully-Connected Layer :}  The last layer is a Fully Connected (FC) layer with Softmax squashing function. At this stage, the real and imaginary parts of $\mathbb{C}$-CNN are treated as if they were two real numbers and having their individual weights, and the $\mathbb{C}$-CNN loses its "complex" sense.
	
	\item \textit{Loss Function :} The FC layer presents probability scores for each of the classes. The categorical cross entropy loss function is employed to evaluate the loss.
\end{enumerate}


  \begin{figure}[htb]
 	\centering
 	\epsfxsize=5cm
 	{\epsfbox{1}}\ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \
 	\epsfxsize=6.75cm
 	{\epsfbox{23}}\ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \
 		\epsfxsize=5cm
 	{\epsfbox{ARCH}}
 	\caption{Architecture of the first residual block in stage 1 [LEFT], and that in stages 2 and 3 [RIGHT]; General architecture of both $\mathbb{R}$-CNN and $\mathbb{C}$-CNN [BOTTOM]}
 	\label{fig:architecture}
 \end{figure}
 

 
 